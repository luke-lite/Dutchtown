{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4eec2-37de-433b-b5c9-2d83d2fb3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ce61f-6528-4093-972f-dfcfaf839ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = pd.read_csv('grav-jeff-parcels.csv')\n",
    "nhd_num_list = [16, 17, 19, 30]\n",
    "mask = parcels['NBRHD'].isin(nhd_num_list)\n",
    "parcels_df = parcels[mask]\n",
    "parcels_df['SITEADDR'] = parcels_df['SITEADDR'].replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "csv = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b6552-5885-4274-ae9e-50a97e528858",
   "metadata": {},
   "outputs": [],
   "source": [
    "gj_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "gj_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])\n",
    "\n",
    "lra_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "lra_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])\n",
    "\n",
    "non_lra_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "non_lra_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1f47b-1de4-4444-ab84-e52c2623603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacancyDataTransformer():\n",
    "\n",
    "    def load_raw_df(self, csv):\n",
    "        self.raw_df = pd.read_csv(csv)\n",
    "        return self.raw_df\n",
    "\n",
    "    def create_regional_df(self, raw_df, parcel_df):\n",
    "\n",
    "        # nhd_names = ['Gravois Park', 'Benton Park West', 'Dutchtown', 'Mount Pleasant']\n",
    "        # mask = self.raw_df['NhdName'].isin(nhd_names)\n",
    "        # regional_df = raw_df[mask]\n",
    "\n",
    "        full_nhds = ['Gravois Park', 'Benton Park West']\n",
    "        partial_nhds = ['Dutchtown', 'Mount Pleasant']\n",
    "\n",
    "        full_mask = raw_df['NhdName'].isin(full_nhds)\n",
    "        bpw_gp_df = raw_df[full_mask]\n",
    "\n",
    "        partial_mask = raw_df['NhdName'].isin(partial_nhds)\n",
    "        partial_df = raw_df[partial_mask]\n",
    "\n",
    "        matching_parcels = []\n",
    "        for handle in list(partial_df['Handle']):\n",
    "            if handle in list(parcels_df['HANDLE']):\n",
    "                matching_parcels.append(handle)\n",
    "\n",
    "        handle_mask = partial_df['NhdName'].isin(matching_parcels)\n",
    "        handle_match_df = partial_df[handle_mask]\n",
    "\n",
    "        partial_df['SITEADDR'] = partial_df.apply(combine_columns, axis=1)\n",
    "        \n",
    "        matching_parcels = []\n",
    "        for site_addr in list(partial_df['SITEADDR']):\n",
    "            if site_addr in list(parcels_df['SITEADDR']):\n",
    "                matching_parcels.append(site_addr)\n",
    "\n",
    "        addr_mask = partial_df['SITEADDR'].isin(matching_parcels)\n",
    "        addr_match_df = partial_df[addr_mask]\n",
    "\n",
    "        joint_df = pd.concat([handle_match_df, addr_match_df], ignore_index=True)\n",
    "        dt_mp_df = joint_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "        regional_df = pd.concat([bpw_gp_df, dt_mp_df], ignore_index=True)\n",
    "        \n",
    "        return regional_df\n",
    "\n",
    "    def calc_vacancy_cats(self, df, aggregate_df):\n",
    "        counts = df['VacancyCat'].value_counts().to_dict()\n",
    "        cnt_cols = ['Indeterminant', 'Possible', 'Very Likely', 'Definite']\n",
    "        for col in cnt_cols:\n",
    "            if col not in counts.keys():\n",
    "                counts[col] = 0\n",
    "                \n",
    "        data = [self.date] + [counts['Indeterminant'], counts['Possible'], counts['Very Likely'], counts['Definite']]\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = data\n",
    "\n",
    "    def calc_burden_cats(self, df, aggregate_df):\n",
    "        counts = df['BurdenCat'].value_counts().to_dict()\n",
    "        cnt_cols = ['Zero', 'Minimal', 'Very Low', 'Low', 'Medium Low', 'Medium', 'Medium High', 'Somewhat High', 'High', 'Very High', 'Extremely High']\n",
    "        for col in cnt_cols:\n",
    "            if col not in counts.keys():\n",
    "                counts[col] = 0\n",
    "                \n",
    "        zero_cat = counts['Zero']\n",
    "        low_cat = sum([counts['Minimal'], counts['Very Low'], counts['Low']])\n",
    "        med_cat = sum([counts['Medium Low'], counts['Medium'], counts['Medium High'], counts['Somewhat High']])\n",
    "        high_cat = sum([counts['High'], counts['Very High'], counts['Extremely High']])\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = [self.date, zero_cat, low_cat, med_cat, high_cat]\n",
    "\n",
    "    def calc_groupby_counts(self, df, cat_list, region):\n",
    "        \n",
    "        # valid = {'stl','bpw-gp', 'dutchtown', 'gravois-jefferson'}\n",
    "        # if region not in valid:\n",
    "        #     raise ValueError(\"results: status must be one of %r.\" % valid)\n",
    "        \n",
    "        for cat in cat_list:\n",
    "\n",
    "            # VacancyCat:\n",
    "            vac_df = df.groupby(cat)['VacancyCat'].value_counts().to_frame().unstack()\n",
    "            vac_df.columns = vac_df.columns.droplevel()\n",
    "            vac_df.fillna(value=0, inplace=True)\n",
    "            vac_value_name = vac_df.columns.name\n",
    "            vac_index_name = vac_df.index.name\n",
    "\n",
    "            vac_dict = vac_df.to_dict() # sdflkjasd;lfja;slfjklsd;fkjls;dkfjlsdfja;lsfdjl;skdjflsdjflsdjfklsdkfjl;sdkfjaksjdfasjdf;ldsf\n",
    "            key = list(vac_dict.keys())[0]\n",
    "            b_types = list(vac_dict[key].keys())\n",
    "            v_cols = ['Indeterminant', 'Possible', 'Very Likely', 'Definite']\n",
    "\n",
    "            for col in v_cols:\n",
    "                if col not in vac_dict.keys():\n",
    "                    vac_dict[col] = {}\n",
    "                    for b in b_types:\n",
    "                        vac_dict[col][b] = 0\n",
    "\n",
    "            vac_df = pd.DataFrame(vac_dict)\n",
    "            \n",
    "            vac_df = vac_df[['Indeterminant', 'Possible', 'Very Likely', 'Definite']]\n",
    "            vac_df.rename(columns={'Indeterminant': 'V_Indeterminant',\n",
    "                               'Possible': 'V_Possible',\n",
    "                               'Very Likely': 'V_Very_Likely',\n",
    "                               'Definite': 'V_Definite'},\n",
    "                          inplace=True)\n",
    "            vac_df.reset_index(inplace=True, names='Type')\n",
    "            vac_df.insert(loc=0, column='Date', value=self.date)\n",
    "            # vac_df.to_csv(f'data/temp/{vac_index_name.lower()}_vacancy_data/{region}/{region}_{vac_index_name}_{vac_value_name}_{self.date}.csv')\n",
    "            \n",
    "\n",
    "            # BurdenCat\n",
    "            bur_df =  df.groupby(cat)['BurdenCat'].value_counts().to_frame().unstack()\n",
    "            bur_df.columns = bur_df.columns.droplevel()\n",
    "            bur_df.fillna(value=0, inplace=True)\n",
    "            bur_index_name = bur_df.index.name\n",
    "            bur_value_name = bur_df.columns.name\n",
    "\n",
    "            bur_dict = bur_df.to_dict()\n",
    "            key = list(bur_dict.keys())[0]\n",
    "            b_types = list(bur_dict[key].keys())\n",
    "            b_cols = ['Zero', 'Minimal', 'Very Low', 'Low', 'Medium Low', 'Medium', 'Medium High', 'Somewhat High', 'High', 'Very High', 'Extremely High']\n",
    "\n",
    "            for col in b_cols:\n",
    "                if col not in bur_dict.keys():\n",
    "                    bur_dict[col] = {}\n",
    "                    for b in b_types:\n",
    "                        bur_dict[col][b] = 0\n",
    "\n",
    "            bur_df = pd.DataFrame(bur_dict).reset_index(names='Type')\n",
    "            \n",
    "            bur_df['B_Zero'] = bur_df['Zero']\n",
    "            bur_df['B_Low'] = bur_df['Minimal'] + bur_df['Very Low'] + bur_df['Low']\n",
    "            bur_df['B_Medium'] = bur_df['Medium Low'] + bur_df['Medium'] + bur_df['Medium High'] + bur_df['Somewhat High']\n",
    "            bur_df['B_High'] = bur_df['High'] + bur_df['Very High'] + bur_df['Extremely High']\n",
    "            bur_df.reset_index(inplace=True)\n",
    "            bur_df.insert(loc=0, column='Date', value=self.date)\n",
    "            bur_df = bur_df[['Date', 'Type', 'B_Zero', 'B_Low', 'B_Medium', 'B_High']]\n",
    "            # bur_df.to_csv(f'data/temp/{vac_index_name.lower()}_burden_data/{region}/{region}_{bur_index_name}_{bur_value_name}_{self.date}.csv')\n",
    "            \n",
    "        return vac_df, bur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1638a79-1552-4ad7-ae20-647495db526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = VacancyTransformer(csv)\n",
    "raw = vt.load_raw_df()\n",
    "\n",
    "lra = raw.loc[raw['IsLRA'].isin([True])]\n",
    "non_lra = raw.loc[~raw['IsLRA'].isin([True])]\n",
    "\n",
    "# calc the grav-jeff totals\n",
    "reg_df = vt.create_regional_df(raw_df=raw, parcel_df=parcels_df)\n",
    "vt.calc_vacancy_cats(df=reg_df, aggregate_df=gj_vacancy_cat_df)\n",
    "vt.calc_burden_cats(df=reg_df, aggregate_df=gj_burden_cat_df)\n",
    "reg_vac, reg_bur = vt.calc_groupby_counts(df=reg_df, cat_list=['Type'], region='gravois-jefferson')\n",
    "\n",
    "# calc the lra totals\n",
    "lra_df = vt.create_regional_df(raw_df=lra, parcel_df=parcels_df)\n",
    "vt.calc_vacancy_cats(df=lra_df, aggregate_df=lra_vacancy_cat_df)\n",
    "vt.calc_burden_cats(df=lra_df, aggregate_df=lra_burden_cat_df)\n",
    "lra_vac, lra_bur = vt.calc_groupby_counts(df=lra_df, cat_list=['Type'], region='gj_lra')\n",
    "\n",
    "# calc the non-lra totals\n",
    "non_lra_df = vt.create_regional_df(raw_df=non_lra, parcel_df=parcels_df)\n",
    "vt.calc_vacancy_cats(df=non_lra_df, aggregate_df=non_lra_vacancy_cat_df)\n",
    "vt.calc_burden_cats(df=non_lra_df, aggregate_df=non_lra_burden_cat_df)\n",
    "non_lra_vac, non_lra_bur = vt.calc_groupby_counts(df=non_lra_df, cat_list=['Type'], region='gj_non-lra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b86df6-bc4d-461a-9e98-59b74ad1590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gj_burden_cat_df.to_csv('data/temp/gravois-jefferson_burden.csv')\n",
    "# gj_vacancy_cat_df.to_csv('data/temp/gravois-jefferson_vacancy.csv')\n",
    "\n",
    "# lra_burden_cat_df.to_csv('data/temp/gj_lra_burden.csv')\n",
    "# lra_vacancy_cat_df.to_csv('data/temp/gj_lra_vacancy.csv')\n",
    "\n",
    "# non_lra_burden_cat_df.to_csv('data/temp/gj_non-lra_burden.csv')\n",
    "# non_lra_vacancy_cat_df.to_csv('data/temp/gj_non-lra_vacancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a15fb-2b89-4299-9438-e3bd4ba95ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95326a-c51b-4733-a989-7c7b0239976a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b6458-e4f3-44bb-83d4-70c679a2345f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b7fc2-e4fb-48d4-803b-7c0249af8cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad47446-e25e-425d-9357-89189e22431d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38897dc-e98a-4c65-a29f-78e0b9e50025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c527a2-61b5-4a5a-807a-0beb325901a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'09A': non-negligient manslaughter and murder\n",
    "'11A': rape\n",
    "'13A', '13A*': aggravated assault"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dutchtown-env",
   "language": "python",
   "name": "dutchtown-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
