{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1d3077-0019-4c2d-9540-ccff357773ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ecd60a-e430-4423-b19e-3cab1c96e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geostl nghbd codes:\n",
    "    # gravois park = 19\n",
    "    # benton park west = 30\n",
    "    # dutchtown = 16\n",
    "    # mount pleasant = 17\n",
    "# https://dynamic.stlouis-mo.gov/citydata/newdesign/sqlsearch.cfm\n",
    "# gravois_total_parcels = 1733\n",
    "# benton_park_west_total_parcels = 1693\n",
    "# dutchtown_total_parcels = 4850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420ffa74-43d1-4a34-a247-0a91ea60de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = 'stl_vacancy_data/'\n",
    "path = \"stl_vacancy_data/*.csv\"\n",
    "csv_list = []\n",
    "\n",
    "gj_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "gj_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])\n",
    "\n",
    "for fname in glob.glob(path):\n",
    "    csv_name = re.findall(r'stl_vacancy_data_\\d\\d\\d\\d-\\d\\d-\\d\\d.csv', fname)[0]\n",
    "    csv_list.append(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26477324-504d-4d1d-8832-d980e5c5bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = pd.read_csv('grav-jeff-parcels.csv')\n",
    "nhd_num_list = [16, 17, 19, 30]\n",
    "mask = parcels['NBRHD'].isnin(nhd_num_list)\n",
    "parcels_df = parcels[mask]\n",
    "\n",
    "parcels_df['SITEADDR'] = parcels_df['SITEADDR'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496362c-68b2-41b0-9554-68844ef79fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gj_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "gj_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3588e4e-a54c-4fa4-8b7c-1266063d6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(row):\n",
    "    return str(row['StAddrNum']) + ' ' + row['StNameFull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b858f-43c5-43ce-bba5-21be164c8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacancyTransformer():\n",
    "    def __init__(self, csv_name):\n",
    "        self.date = re.findall(r'\\d\\d\\d\\d-\\d\\d-\\d\\d', csv_name)[0]\n",
    "        self.csv_name = csv_name\n",
    "        \n",
    "    def load_raw_df(self):\n",
    "        self.raw_df = pd.read_csv(csv_folder+self.csv_name)\n",
    "        return self.raw_df\n",
    "\n",
    "    def create_regional_df(self, parcel_df):\n",
    "\n",
    "        # nhd_names = ['Gravois Park', 'Benton Park West', 'Dutchtown', 'Mount Pleasant']\n",
    "        # mask = self.raw_df['NhdName'].isin(nhd_names)\n",
    "        # regional_df = raw_df[mask]\n",
    "\n",
    "        full_nhds = ['Gravois Park', 'Benton Park West']\n",
    "        partial_nhds = ['Dutchtown', 'Mount Pleasant']\n",
    "\n",
    "        full_mask = self.raw_df['NhdName'].isin(full_nhds)\n",
    "        bpw_gp_df = raw_df[full_mask]\n",
    "\n",
    "        partial_mask = self.raw_df['NhdName'].isin(partial_nhds)\n",
    "        partial_df = raw_df[partial mask]\n",
    "\n",
    "        matching_parcels = []\n",
    "        for handle in list(partial_nhds['Handle']): #sdlkfjsdlkfjslkdjfslkdjflskdjflksdjflskdjflksdjflsksdjflksdjf\n",
    "            if handle in list(parcels_df['HANDLE']):\n",
    "                matching_parcels.append(handle)\n",
    "\n",
    "        handle_mask = partial_nhds['NhdName'].isin(matching_parcels)\n",
    "        handle_match_df = partial_nhds[handle_mask]\n",
    "\n",
    "        partial_df['SITEADDR'] = partial_df.apply(combine_columns, axis=1)\n",
    "        \n",
    "        matching_parcels = []\n",
    "        for site_addr in list(partial_df['SITEADDR']):\n",
    "            if site_addr in list(parcels_df['SITEADDR']):\n",
    "                matching_parcels.append(site_addr)\n",
    "\n",
    "        addr_mask = partial_nhds['SITEADDR'].isin(matching_parcels)\n",
    "        addr_match_df = partial_nhds[addr_mask]\n",
    "\n",
    "        joint_df = pd.concat([handle_match_df, addr_match_df], ignore_index=True)\n",
    "        regional_df = joint_df.drop_duplicates(ignore_index=True)\n",
    "        \n",
    "        # gj_addr = list(regional_df['SITEADDR'])\n",
    "        # site_mask = parcels['SITEADDR'].isin(gj_addr)\n",
    "        # site_handles = parcels['HANDLE'][site_mask]\n",
    "\n",
    "        # for handle in list(regional_df['Handle']):\n",
    "        #     if handle in list(parcels_df['HANDLE']):\n",
    "        #         matching_parcels.append(handle)\n",
    "        #     elif \n",
    "\n",
    "        return regional_df\n",
    "        \n",
    "    def calc_vacancy_cats(self, df, aggregate_df):\n",
    "        counts = df['VacancyCat'].value_counts()\n",
    "        data = [self.date] + counts[['Indeterminant', 'Possible', 'Very Likely', 'Definite']].tolist()\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = data\n",
    "\n",
    "    def calc_burden_cats(self, df, aggregate_df):\n",
    "        counts = df['BurdenCat'].value_counts()\n",
    "        zero_cat = counts['Zero']\n",
    "        low_cat = sum(counts[['Minimal', 'Very Low', 'Low']])\n",
    "        med_cat = sum(counts[['Medium Low', 'Medium', 'Medium High', 'Somewhat High']])\n",
    "        high_cat = sum(counts[['High', 'Very High', 'Extremely High']])\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = [self.date, zero_cat, low_cat, med_cat, high_cat]\n",
    "\n",
    "    def calc_groupby_counts(self, df, cat_list):\n",
    "        \n",
    "        # valid = {'stl','bpw-gp', 'dutchtown'}\n",
    "        # if region not in valid:\n",
    "        #     raise ValueError(\"results: status must be one of %r.\" % valid)\n",
    "        \n",
    "        for cat in cat_list:\n",
    "            \n",
    "            # VacancyCat:\n",
    "            vac_df = df.groupby(cat)['VacancyCat'].value_counts().to_frame().unstack()\n",
    "            vac_df.columns = vac_df.columns.droplevel()\n",
    "            vac_df.fillna(value=0, inplace=True)\n",
    "            vac_value_name = vac_df.columns.name\n",
    "            vac_index_name = vac_df.index.name\n",
    "            vac_df = vac_df[['Indeterminant', 'Possible', 'Very Likely', 'Definite']]\n",
    "            vac_df.rename(columns={'Indeterminant': 'V_Indeterminant',\n",
    "                               'Possible': 'V_Possible',\n",
    "                               'Very Likely': 'V_Very_Likely',\n",
    "                               'Definite': 'V_Definite'},\n",
    "                          inplace=True)\n",
    "            vac_df.reset_index(inplace=True)\n",
    "            vac_df.insert(loc=0, column='Date', value=self.date)\n",
    "            vac_df.to_csv(f'data/temp/type_vacancy_data/{region}/{region}_{vac_index_name}_{vac_value_name}_{self.date}.csv')\n",
    "\n",
    "            # BurdenCat\n",
    "            bur_df =  df.groupby(cat)['BurdenCat'].value_counts().to_frame().unstack()\n",
    "            bur_df.columns = bur_df.columns.droplevel()\n",
    "            bur_df.fillna(value=0, inplace=True)\n",
    "            bur_index_name = bur_df.index.name\n",
    "            bur_value_name = bur_df.columns.name\n",
    "            bur_df['B_Zero'] = bur_df['Zero']\n",
    "            bur_df['B_Low'] = bur_df['Minimal'] + bur_df['Very Low'] + bur_df['Low']\n",
    "            bur_df['B_Medium'] = bur_df['Medium Low'] + bur_df['Medium'] + bur_df['Medium High'] + bur_df['Somewhat High']\n",
    "            bur_df['B_High'] = bur_df['High'] + bur_df['Very High'] + bur_df['Extremely High']\n",
    "            bur_df.reset_index(inplace=True)\n",
    "            bur_df.insert(loc=0, column='Date', value=self.date)\n",
    "            bur_df = bur_df[['Date', 'Type', 'B_Zero', 'B_Low', 'B_Medium', 'B_High']]\n",
    "            bur_df.to_csv(f'data/temp/type_burden_data/{region}/{region}_{bur_index_name}_{bur_value_name}_{self.date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e0d6d-da64-4b46-a2f6-7e2e13f5be44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29918f-81e4-4c2b-ba4e-9902529c084e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dutchtown-env",
   "language": "python",
   "name": "dutchtown-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
