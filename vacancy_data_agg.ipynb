{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1d3077-0019-4c2d-9540-ccff357773ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ecd60a-e430-4423-b19e-3cab1c96e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geostl nghbd codes:\n",
    "    # gravois park = 19\n",
    "    # benton park west = 30\n",
    "    # dutchtown = 16\n",
    "    # mount pleasant = 17\n",
    "# https://dynamic.stlouis-mo.gov/citydata/newdesign/sqlsearch.cfm\n",
    "# gravois_total_parcels = 1733\n",
    "# benton_park_west_total_parcels = 1693\n",
    "# dutchtown_total_parcels = 4850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420ffa74-43d1-4a34-a247-0a91ea60de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = 'stl_vacancy_data/'\n",
    "path = \"stl_vacancy_data/*.csv\"\n",
    "csv_list = []\n",
    "\n",
    "gj_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "gj_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])\n",
    "\n",
    "for fname in glob.glob(path):\n",
    "    csv_name = re.findall(r'stl_vacancy_data_\\d\\d\\d\\d-\\d\\d-\\d\\d.csv', fname)[0]\n",
    "    csv_list.append(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26477324-504d-4d1d-8832-d980e5c5bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diper\\AppData\\Local\\Temp\\ipykernel_4480\\779168207.py:1: DtypeWarning: Columns (16,23,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  parcels = pd.read_csv('grav-jeff-parcels.csv')\n"
     ]
    }
   ],
   "source": [
    "parcels = pd.read_csv('grav-jeff-parcels.csv')\n",
    "nhd_num_list = [16, 17, 19, 30]\n",
    "mask = parcels['NBRHD'].isin(nhd_num_list)\n",
    "parcels_df = parcels[mask]\n",
    "\n",
    "parcels_df['SITEADDR'] = parcels_df['SITEADDR'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5496362c-68b2-41b0-9554-68844ef79fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gj_vacancy_cat_df = pd.DataFrame(columns=['Date', 'V_Indeterminate', 'V_Possible', 'V_Very_likely', 'V_Definite'])\n",
    "gj_burden_cat_df = pd.DataFrame(columns=['Date', 'B_Zero', 'B_Low', 'B_Medium', 'B_High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3588e4e-a54c-4fa4-8b7c-1266063d6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(row):\n",
    "    return str(row['StAddrNum']) + ' ' + row['StNameFull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "413b858f-43c5-43ce-bba5-21be164c8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacancyTransformer():\n",
    "    def __init__(self, csv_name):\n",
    "        self.date = re.findall(r'\\d\\d\\d\\d-\\d\\d-\\d\\d', csv_name)[0]\n",
    "        self.csv_name = csv_name\n",
    "        \n",
    "    def load_raw_df(self):\n",
    "        self.raw_df = pd.read_csv(csv_folder+self.csv_name)\n",
    "        return self.raw_df\n",
    "\n",
    "    def create_regional_df(self, parcel_df):\n",
    "\n",
    "        # nhd_names = ['Gravois Park', 'Benton Park West', 'Dutchtown', 'Mount Pleasant']\n",
    "        # mask = self.raw_df['NhdName'].isin(nhd_names)\n",
    "        # regional_df = raw_df[mask]\n",
    "\n",
    "        full_nhds = ['Gravois Park', 'Benton Park West']\n",
    "        partial_nhds = ['Dutchtown', 'Mount Pleasant']\n",
    "\n",
    "        full_mask = self.raw_df['NhdName'].isin(full_nhds)\n",
    "        bpw_gp_df = self.raw_df[full_mask]\n",
    "\n",
    "        partial_mask = self.raw_df['NhdName'].isin(partial_nhds)\n",
    "        partial_df = self.raw_df[partial_mask]\n",
    "\n",
    "        matching_parcels = []\n",
    "        for handle in list(partial_df['Handle']):\n",
    "            if handle in list(parcels_df['HANDLE']):\n",
    "                matching_parcels.append(handle)\n",
    "\n",
    "        handle_mask = partial_df['NhdName'].isin(matching_parcels)\n",
    "        handle_match_df = partial_df[handle_mask]\n",
    "\n",
    "        partial_df['SITEADDR'] = partial_df.apply(combine_columns, axis=1)\n",
    "        \n",
    "        matching_parcels = []\n",
    "        for site_addr in list(partial_df['SITEADDR']):\n",
    "            if site_addr in list(parcels_df['SITEADDR']):\n",
    "                matching_parcels.append(site_addr)\n",
    "\n",
    "        addr_mask = partial_df['SITEADDR'].isin(matching_parcels)\n",
    "        addr_match_df = partial_df[addr_mask]\n",
    "\n",
    "        joint_df = pd.concat([handle_match_df, addr_match_df], ignore_index=True)\n",
    "        dt_mp_df = joint_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "        regional_df = pd.concat([bpw_gp_df, dt_mp_df], ignore_index=True)\n",
    "        \n",
    "        # gj_addr = list(regional_df['SITEADDR'])\n",
    "        # site_mask = parcels['SITEADDR'].isin(gj_addr)\n",
    "        # site_handles = parcels['HANDLE'][site_mask]\n",
    "\n",
    "        # for handle in list(regional_df['Handle']):\n",
    "        #     if handle in list(parcels_df['HANDLE']):\n",
    "        #         matching_parcels.append(handle)\n",
    "        #     elif \n",
    "\n",
    "        return regional_df\n",
    "        \n",
    "    def calc_vacancy_cats(self, df, aggregate_df):\n",
    "        counts = df['VacancyCat'].value_counts()\n",
    "        data = [self.date] + counts[['Indeterminant', 'Possible', 'Very Likely', 'Definite']].tolist()\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = data\n",
    "\n",
    "    def calc_burden_cats(self, df, aggregate_df):\n",
    "        counts = df['BurdenCat'].value_counts()\n",
    "        zero_cat = counts['Zero']\n",
    "        low_cat = sum(counts[['Minimal', 'Very Low', 'Low']])\n",
    "        med_cat = sum(counts[['Medium Low', 'Medium', 'Medium High', 'Somewhat High']])\n",
    "        high_cat = sum(counts[['High', 'Very High', 'Extremely High']])\n",
    "        \n",
    "        aggregate_df.loc[len(aggregate_df.index)] = [self.date, zero_cat, low_cat, med_cat, high_cat]\n",
    "\n",
    "    def calc_groupby_counts(self, df, cat_list):\n",
    "        \n",
    "        # valid = {'stl','bpw-gp', 'dutchtown'}\n",
    "        # if region not in valid:\n",
    "        #     raise ValueError(\"results: status must be one of %r.\" % valid)\n",
    "        \n",
    "        for cat in cat_list:\n",
    "            \n",
    "            # VacancyCat:\n",
    "            vac_df = df.groupby(cat)['VacancyCat'].value_counts().to_frame().unstack()\n",
    "            vac_df.columns = vac_df.columns.droplevel()\n",
    "            vac_df.fillna(value=0, inplace=True)\n",
    "            vac_value_name = vac_df.columns.name\n",
    "            vac_index_name = vac_df.index.name\n",
    "            vac_df = vac_df[['Indeterminant', 'Possible', 'Very Likely', 'Definite']]\n",
    "            vac_df.rename(columns={'Indeterminant': 'V_Indeterminant',\n",
    "                               'Possible': 'V_Possible',\n",
    "                               'Very Likely': 'V_Very_Likely',\n",
    "                               'Definite': 'V_Definite'},\n",
    "                          inplace=True)\n",
    "            vac_df.reset_index(inplace=True)\n",
    "            vac_df.insert(loc=0, column='Date', value=self.date)\n",
    "            vac_df.to_csv(f'data/temp/type_vacancy_data/{region}/{region}_{vac_index_name}_{vac_value_name}_{self.date}.csv')\n",
    "\n",
    "            # BurdenCat\n",
    "            bur_df =  df.groupby(cat)['BurdenCat'].value_counts().to_frame().unstack()\n",
    "            bur_df.columns = bur_df.columns.droplevel()\n",
    "            bur_df.fillna(value=0, inplace=True)\n",
    "            bur_index_name = bur_df.index.name\n",
    "            bur_value_name = bur_df.columns.name\n",
    "            bur_df['B_Zero'] = bur_df['Zero']\n",
    "            bur_df['B_Low'] = bur_df['Minimal'] + bur_df['Very Low'] + bur_df['Low']\n",
    "            bur_df['B_Medium'] = bur_df['Medium Low'] + bur_df['Medium'] + bur_df['Medium High'] + bur_df['Somewhat High']\n",
    "            bur_df['B_High'] = bur_df['High'] + bur_df['Very High'] + bur_df['Extremely High']\n",
    "            bur_df.reset_index(inplace=True)\n",
    "            bur_df.insert(loc=0, column='Date', value=self.date)\n",
    "            bur_df = bur_df[['Date', 'Type', 'B_Zero', 'B_Low', 'B_Medium', 'B_High']]\n",
    "            bur_df.to_csv(f'data/temp/type_burden_data/{region}/{region}_{bur_index_name}_{bur_value_name}_{self.date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508e0d6d-da64-4b46-a2f6-7e2e13f5be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diper\\AppData\\Local\\Temp\\ipykernel_4480\\546464046.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_df['SITEADDR'] = partial_df.apply(combine_columns, axis=1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'region' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m d\u001b[38;5;241m.\u001b[39mcalc_vacancy_cats(df\u001b[38;5;241m=\u001b[39mreg_df, aggregate_df\u001b[38;5;241m=\u001b[39mgj_vacancy_cat_df)\n\u001b[0;32m      5\u001b[0m d\u001b[38;5;241m.\u001b[39mcalc_burden_cats(df\u001b[38;5;241m=\u001b[39mreg_df, aggregate_df\u001b[38;5;241m=\u001b[39mgj_burden_cat_df)\n\u001b[1;32m----> 6\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_groupby_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreg_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 96\u001b[0m, in \u001b[0;36mVacancyTransformer.calc_groupby_counts\u001b[1;34m(self, df, cat_list)\u001b[0m\n\u001b[0;32m     94\u001b[0m vac_df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     95\u001b[0m vac_df\u001b[38;5;241m.\u001b[39minsert(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate)\n\u001b[1;32m---> 96\u001b[0m vac_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/temp/type_vacancy_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mregion\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvac_index_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvac_value_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# BurdenCat\u001b[39;00m\n\u001b[0;32m     99\u001b[0m bur_df \u001b[38;5;241m=\u001b[39m  df\u001b[38;5;241m.\u001b[39mgroupby(cat)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBurdenCat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39munstack()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'region' is not defined"
     ]
    }
   ],
   "source": [
    "d = VacancyTransformer(csv_list[0])\n",
    "d.load_raw_df()\n",
    "reg_df = d.create_regional_df(parcel_df=parcels_df)\n",
    "d.calc_vacancy_cats(df=reg_df, aggregate_df=gj_vacancy_cat_df)\n",
    "d.calc_burden_cats(df=reg_df, aggregate_df=gj_burden_cat_df)\n",
    "d.calc_groupby_counts(df=reg_df, cat_list=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29918f-81e4-4c2b-ba4e-9902529c084e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dutchtown-env",
   "language": "python",
   "name": "dutchtown-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
